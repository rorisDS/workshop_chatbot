{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rorisDS/workshop_chatbot/blob/main/Workshop_Chatbot_ES.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98zFf7-n4h1_"
      },
      "source": [
        "# Construyendo un chatbot basado en Inteligencia Artificial\n",
        "\n",
        "Este notebook ha sido creado para un workshop durante el *Foro Tecnolóxico de Emprego* de 2022 de la Universidad de Vigo por [Víctor Manuel Alonso Rorís](https://es.linkedin.com/in/victor-roris/en) de la empresa [DataSpartan](http://dataspartan.es/)\n",
        "\n",
        "La presentación y resto de código asociado está disponible en el github: https://github.com/rorisDS/workshop_chatbot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLU5RViJh0qB"
      },
      "source": [
        "## Qué es un chatbot\n",
        "\n",
        "Un chatbot es un agente software que permite automatizar conversaciones en lenguaje natural. \n",
        "\n",
        "El lenguaje natural es el lenguaje hablado por humanos. Este es desestructurado, por lo tanto difícil de procesar por las máquinas. En la construcción de chatbots se utiliza el área del Procesado de Lenguaje Natural (o NLP por sus siglas en inglés) para interpretar los mensajes. En general, este proceso de interpretación es lo que llamamos NLU (Natural Language Understanding) y que en los chatbots tratan de identificar los componentes del mensaje:\n",
        "\n",
        " - *Intents*: Intención del usuario expresada en el mensaje\n",
        " - *Entities*: Información adicional del mensaje\n",
        "\n",
        "A modo general, la arquitectura de un chatbot simple seguiría el siguiente diagrama: \n",
        "\n",
        "![arquitectura](https://raw.githubusercontent.com/rorisDS/workshop_chatbot/main/assets/chatbot_architecture.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eoUeZztCkC28"
      },
      "source": [
        "## Implementación\n",
        "\n",
        "Este notebook tiene un objetivo didáctico. En concreto, aprender los diferentes componentes y ver como se coordinan a fin de automatizar conversaciones muy básicas. Por lo tanto, el código aquí presentado es simple y puede presentar errores. Si estas buscando construir un chatbot orientado a negocio dispones de diferentes librerías especializadas que te pueden servir de base (por ejemplo, [RASA](https://rasa.com/)) \n",
        "\n",
        "\n",
        "En este ejemplo vamos a desarrollar un chatbot llamado **Bea** que permita gestionar consultas y peticiones en una cafetería. En concreto:\n",
        "\n",
        " - **Consultar el horario**\n",
        " - **Consultar el menú**\n",
        " - **Hacer una comanda**\n",
        "\n",
        "La idea es presentar diferentes implementaciones de un chatbot que nos permita profundizar en diferentes tipos de NLUs, desde lo más básico a lo más avanzado. En este sentido presentaremos 3 tipos de componentes NLU:\n",
        "\n",
        " - *Basado en patrones*: identificar patrones en los mensajes del usuario \n",
        " - *Basado en similitud de oraciones*: los mensajes se parecen a los esperados para cada intent. \n",
        " - *Basado en Rasa NLU*: modelo NLP para la identificación de `intents` y `entities`\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8Mf_5XgtUFO"
      },
      "source": [
        "### Instalación de librerias"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTA**: Se recomienda configurar el notebook para disponer de una GPU:\n",
        "\n",
        "```Entorno de ejecución > Cambiar tipo de entorno de ejecución > Acelerador = GPU```\n",
        "\n",
        "De otra forma debería seguir funcionando, pero los modelos podrían ir más lentos y pueden producirse reinicios de sesión."
      ],
      "metadata": {
        "id": "UOtpPpQ-7hQT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UyqCJy0EtTdj"
      },
      "outputs": [],
      "source": [
        "# Libreria para descargar y entrenar state-of-the-art modelos NLP pre-entrenados\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8zS_9g5UgR6e"
      },
      "outputs": [],
      "source": [
        "# Permitir asincronia en google colab (rasa nlu)\n",
        "!pip3 install nest_asyncio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R9bkkkKjgR6f"
      },
      "outputs": [],
      "source": [
        "# Version necesaria para rasa nlu\n",
        "!pip install sanic==21.9.3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Version necesaria para rasa nlu\n",
        "!pip install urllib3==1.26.8"
      ],
      "metadata": {
        "id": "kmAid9pEgR6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A09m8IavgR6h"
      },
      "outputs": [],
      "source": [
        "# Rasa, libreria para el desarrollo de chatbots\n",
        "!pip install rasa --use-deprecated=legacy-resolver"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTA**: Tras instalar estas librerias debes reiniciar el entorno para que estas pasen a ser accesibles en el código:\n",
        "\n",
        "```Entorno de ejecución > Reiniciar entorno de ejecución```\n",
        "\n",
        "Tras ello, reanuda la ejecucion de las celdas desde este punto."
      ],
      "metadata": {
        "id": "GZuSMYlCg28W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a6Bn_x7ggR6h"
      },
      "outputs": [],
      "source": [
        "# Necesario, para reinicio\n",
        "!pip install -U ipython"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "FPKajl6ugzu5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if the installation was correct\n",
        "from urllib3.util.ssl_ import PROTOCOL_TLS"
      ],
      "metadata": {
        "id": "5HAXrWOkgR6j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eThPyC46onz0"
      },
      "source": [
        "### Capa de BACKEND\n",
        "\n",
        "Este componente es el encargado de comunicar el chatbot con la API de la cafetería, permitiendo así acceder a los datos (p. ej., almacenados en una base de datos) o ejecutar acciones.   \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Horario de la cafeteria\n",
        "timetable_db = [\n",
        "      {\n",
        "          \"days\" : [\"Lunes\"],\n",
        "          \"timetable\" : \"08:30-20:00\"\n",
        "      },\n",
        "      {\n",
        "          \"days\" : [\"Martes\", \"Miércoles\", \"Jueves\"],\n",
        "          \"timetable\" : \"08:00-20:00\"\n",
        "      },\n",
        "      {\n",
        "          \"days\" : [\"Viernes\"],\n",
        "          \"timetable\" : \"08:00-17:00\"\n",
        "      }\n",
        "  ]\n",
        "\n",
        "# Menú de la cafetería\n",
        "menu_db = {\n",
        "    \"1\" : {\n",
        "        \"item\": \"Bocadillo de jamón serrano\",\n",
        "        \"group\": \"Bocadillo\",\n",
        "        \"cost\": 5.30,\n",
        "        \"veg\": False,\n",
        "    },\n",
        "    \"2\" : {\n",
        "        \"item\": \"Bocadillo de queso\",\n",
        "        \"group\": \"Bocadillo\",\n",
        "        \"cost\": 4.00,\n",
        "        \"veg\": True,\n",
        "    },\n",
        "    \"3\" : {\n",
        "        \"item\": \"Bocadillo de bacon y queso\",\n",
        "        \"group\": \"Bocadillo\",\n",
        "        \"cost\": 5.00,\n",
        "        \"veg\": False,\n",
        "    },\n",
        "    \"4\" : {\n",
        "        \"item\": \"Pechuga de pollo\",\n",
        "        \"group\": \"Plato combinado\",\n",
        "        \"cost\": 6.00,\n",
        "        \"veg\": True,\n",
        "    },\n",
        "    \"5\" : {\n",
        "        \"item\": \"Tofu con pure de guisantes\",\n",
        "        \"group\": \"Plato combinado\",\n",
        "        \"cost\": 7.00,\n",
        "        \"veg\": True,\n",
        "    },\n",
        "    \"6\" : {\n",
        "        \"item\": \"Pimientos rellenos de champiñones\",\n",
        "        \"group\": \"Plato combinado\",\n",
        "        \"cost\": 6.00,\n",
        "        \"veg\": True,\n",
        "    },\n",
        "    \"7\" : {\n",
        "        \"item\": \"Agua\",\n",
        "        \"group\": \"Bebida\",\n",
        "        \"cost\": 0.80,\n",
        "        \"veg\": None,\n",
        "    },\n",
        "    \"8\" : {\n",
        "        \"item\": \"Coca-Cola\",\n",
        "        \"group\": \"Bebida\",\n",
        "        \"cost\": 1.10,\n",
        "        \"veg\": None,\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "Dissw_qVHu3K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "class Backend:\n",
        "  timetable_db = None\n",
        "  menu_db = None\n",
        "  order_id = None\n",
        "  cooking_orders = None\n",
        "\n",
        "  def __init__(self):\n",
        "    global timetable_db\n",
        "    global menu_db \n",
        "    self.timetable_db = timetable_db\n",
        "    self.menu_db = menu_db\n",
        "    self.order_id = 1\n",
        "    self.cooking_orders = {}\n",
        "\n",
        "  # ---- TIMETABLE\n",
        "\n",
        "  def get_timetable(self) -> list:\n",
        "    \"\"\"Devuelve el horario de la cafeteria\"\"\"\n",
        "    return self.timetable_db\n",
        "\n",
        "  # ---- MENU\n",
        "\n",
        "  def get_menu(self) -> dict:\n",
        "    \"\"\"Recupera el menu de la cafeteria\"\"\"\n",
        "    return self.menu_db\n",
        "\n",
        "  def get_menu_item(self, item_ids: list) -> list:\n",
        "    \"\"\"Recupera los menus que se asocien a los IDs dados\"\"\"\n",
        "    if type(item_ids) != list:\n",
        "      item_ids = [item_ids]\n",
        "    return [self.menu_db[item_id] for item_id in item_ids if item_id in self.menu_db]\n",
        "\n",
        "  # ---- ORDER\n",
        "\n",
        "  def new_order(self, menus: list) -> str:\n",
        "    \"\"\"Registra una comanda y asigna un ID\"\"\"\n",
        "    self.cooking_orders[self.order_id] = menus\n",
        "    assigned_id = f\"BEA{self.order_id}\"\n",
        "    self.order_id += 1\n",
        "    return assigned_id\n",
        "\n",
        "  def check_order(self, asked_order_id: str) -> bool:\n",
        "    \"\"\"Consulta si la comanda esta disponible para recoger\"\"\"\n",
        "    if asked_order_id not in self.cooking_orders:\n",
        "      return True\n",
        "    ready = bool(random.getrandbits(1))\n",
        "    if ready:\n",
        "      del self.cooking_orders[asked_order_id]\n",
        "    return ready"
      ],
      "metadata": {
        "id": "d_xjgpNbH5l4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBaKisCbhoFf"
      },
      "source": [
        "### NLG (Natural Language Generation)\n",
        "\n",
        "Componente destinado a la generación de lenguaje natural a fin de dar respuesta al usuario humano. \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NLG:\n",
        "\n",
        "  @staticmethod\n",
        "  def say_hi() -> str:\n",
        "    return \"Hola, mi nombre es Bea.\\nSoy el chatbot de tu cafetería de referencia y mi objetivo es ayudarte con tus consultas y peticiones. Solo dime qué quieres que haga por ti.\"\n",
        "\n",
        "  @staticmethod\n",
        "  def say_hi_respond(username: str=None) -> str:\n",
        "    if username == None:\n",
        "      username = \"\"\n",
        "    return f\"Buenas {username}, ¿qué puedo hacer por ti?\"\n",
        "\n",
        "  @staticmethod\n",
        "  def say_bye() -> str:\n",
        "    return \"Gracias por tu visita, vuelve pronto!\"\n",
        "\n",
        "  @staticmethod\n",
        "  def say_nounderstand() -> str:\n",
        "    return \"Lo siento no he entendido tu mensaje\"\n",
        "\n",
        "  @staticmethod\n",
        "  def say_cancel_accept() -> str:\n",
        "    return \"Perfecto, he cancelado tu consulta\"\n",
        "\n",
        "  @staticmethod\n",
        "  def say_commands() -> str:\n",
        "    return \"\"\"Puedes preguntarme los siguientes comandos:\n",
        "      - Escribe: `horario` para conocer nuestro horario de apertura.\n",
        "      - Escribe: `menú` para conocer nuestra carta.\n",
        "      - Escribe: `pedir` para pedir algo de nuestra carta.\"\"\"\n",
        "\n",
        "  @staticmethod\n",
        "  def say_timetable(timetable: dict) -> str:\n",
        "    if timetable is None:\n",
        "      return \"Actualmente no dispongo de esa información\"\n",
        "\n",
        "    if len(timetable)==0:\n",
        "      return \"La cafetería esta cerrada hasta nuevo aviso\"\n",
        "\n",
        "    timetable_response = \"\"\n",
        "    for entry in timetable:\n",
        "      if len(entry[\"days\"]) == 1:\n",
        "        timetable_response += f'\\nEl {entry[\"days\"][0]} nuestro horario {entry[\"timetable\"]}.'\n",
        "      else:\n",
        "        timetable_response += f'\\nLos { \", \".join([day for day in entry[\"days\"]][:-1])} y {entry[\"days\"][-1]} nuestro horario es {entry[\"timetable\"]}.'\n",
        "    return timetable_response[1:] # Eliminamos el primer salto de linea\n",
        "\n",
        "  @staticmethod\n",
        "  def say_menu(menu:dict) -> str:  \n",
        "    menu_response = \"Nuestras opciones en la carta son : \"\n",
        "\n",
        "    for item_id in menu:\n",
        "      menu_option = menu[item_id]\n",
        "      menu_response += f'\\n - {menu_option[\"item\"]} por {menu_option[\"cost\"]} euros. Código de comanda: {item_id}'\n",
        "    return menu_response\n",
        "\n",
        "  @staticmethod\n",
        "  def say_order_question() -> str:\n",
        "    return \"Indica el código(s) de comanda de tu selección (p. ej., '1, 7' para seleccionar la opción 1 y 7):\"\n",
        "\n",
        "  @staticmethod\n",
        "  def say_complete_order(orders: list, order_id: str) -> str:\n",
        "    if type(orders) != list:\n",
        "      orders = [orders]\n",
        "\n",
        "    # Lista el nombre de los platos seleccionados\n",
        "    order_names = \"\"\n",
        "    if len(orders) == 1:\n",
        "      order_names = orders[0][\"item\"]\n",
        "    else:\n",
        "      order_names = \", \".join([order[\"item\"] for order in orders][:-1]) \n",
        "      order_names += f' y {orders[-1][\"item\"]}'\n",
        "    order_response = f\"Has seleccionado: {order_names} \\n\"\n",
        "\n",
        "    # Calcula el total\n",
        "    total = sum([float(order[\"cost\"]) for order in orders])\n",
        "    order_response += f\"El total de tu pedido asciende a {total} euros.\\n\"\n",
        "\n",
        "    # Identificador de la comanda\n",
        "    order_response += f\"Tu pedido tiene el ID : '{order_id}'.\\n\"\n",
        "\n",
        "    order_response += f\"Pasa por la barra en un rato a recogerlo!\"\n",
        "\n",
        "    return order_response\n",
        "\n",
        "  @staticmethod\n",
        "  def say_order_ready(ready: bool, order_id: str) -> str:\n",
        "    if ready:\n",
        "      return f\"Tu comanda con id {order_id} está disponible. Pasa por la barra a recogerla.\"\n",
        "    return f\"Tu comanda con id {order_id} aún está no esta disponible.\""
      ],
      "metadata": {
        "id": "E0CJKKnaK0je"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKjxE60szXs_"
      },
      "source": [
        "### Lógica Conversacional\n",
        "\n",
        "Componente que gestiona la conversación. Para ello, es el encargado de coordinar a los diferentes componentes y mantener el estado."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ConversationManager():\n",
        "  \"\"\"\n",
        "  Componente que gestiona la automatización de la conversación y la lógica\n",
        "  de interacción con el backend\n",
        "  \"\"\"\n",
        "  \n",
        "  backend = None\n",
        "  nlg = None\n",
        "  nlu_component = None\n",
        "  close_conversation = None\n",
        "  order_state = None\n",
        "\n",
        "  def __init__(self, nlu_component, static_patterns = False):\n",
        "    \n",
        "    # Asigna componentes\n",
        "    self.nlu_component = nlu_component\n",
        "    self.backend = Backend()\n",
        "    self.nlg = NLG()\n",
        "\n",
        "    # La version basada en patrones fija los comandos de entrada\n",
        "    self.static_patterns = static_patterns\n",
        "    # La conversacion esta abierta \n",
        "    self.close_conversation = False\n",
        "    # No se inicio el estado de comanda \n",
        "    self.order_state = False\n",
        "\n",
        "\n",
        "  def is_last_message(self):\n",
        "    \"\"\"Comprueba si el chatbot da por finalizada la conversacion\"\"\"\n",
        "    return self.close_conversation\n",
        "\n",
        "  def init_conversation(self):\n",
        "    \"\"\"El mensaje con el que el chatbot inicia la conversacion con el usuario\"\"\"\n",
        "    self.close_conversation = False\n",
        "    response = self.nlg.say_hi()\n",
        "    if self.static_patterns:\n",
        "      response += \"\\n\" + self.nlg.say_commands()\n",
        "    return response\n",
        "\n",
        "  def _get_entity_values(self, entities, keyword, only_one=False):\n",
        "    entity_values = [entity[\"value\"] for entity in entities if entity[\"entity\"] == keyword]\n",
        "    if only_one:\n",
        "      if len(entity_values)>0:\n",
        "        return entity_values[0]\n",
        "      else:\n",
        "        return None\n",
        "    return entity_values\n",
        "    \n",
        "  \n",
        "  def logic(self, user_message):\n",
        "    \"\"\"Logica que controla el chatbot\"\"\"\n",
        "\n",
        "    if self.order_state:\n",
        "      # Proceso de solicitar una comanda\n",
        "      return self._order_logic(user_message)\n",
        "    else:\n",
        "      # Logica asociada a la gestion de los comandos generales\n",
        "      return self._general_logic(user_message)\n",
        "    \n",
        "  def _general_logic(self, user_message):\n",
        "    \"\"\"Logica asociada a la gestion de los comandos generales\"\"\"\n",
        "\n",
        "    # Llama al NLU para interpretar el mensaje\n",
        "    intent, entities = self.nlu_component(user_message)\n",
        "\n",
        "    if intent == \"greet\":\n",
        "      # Extrae el username de las entities (de existir)\n",
        "      username = self._get_entity_values(entities=entities,\n",
        "                                         keyword=\"username\",\n",
        "                                         only_one=True)\n",
        "      response = self.nlg.say_hi_respond(username)\n",
        "      return response\n",
        "\n",
        "    if intent == \"timetable\":\n",
        "      timetable_data = self.backend.get_timetable()\n",
        "      response = self.nlg.say_timetable(timetable_data)\n",
        "      return response\n",
        "\n",
        "    if intent == \"menu\":\n",
        "      menu_data = self.backend.get_menu()\n",
        "      response = self.nlg.say_menu(menu_data)\n",
        "      return response\n",
        "\n",
        "    if intent == \"order\":\n",
        "      # Cambia el estado del gestor de conversacion (se inicia la comanda)\n",
        "      self.order_state = True\n",
        "      response = self.nlg.say_order_question()\n",
        "      return response\n",
        "\n",
        "    if intent == \"check_order\":\n",
        "      # Extrae el username de las entities (de existir)\n",
        "      asked_order_id = self._get_entity_values(entities=entities,\n",
        "                                         keyword=\"asked_order_id\",\n",
        "                                         only_one=True)\n",
        "      ready = self.backend.check_order(asked_order_id=asked_order_id)\n",
        "      response = self.nlg.say_order_ready(ready, asked_order_id)\n",
        "      return response\n",
        "\n",
        "    if intent == \"bye\":\n",
        "      # Cambia el estado del gestor de conversacion (se cierra la comunicacion)\n",
        "      self.close_conversation = True\n",
        "      response = self.nlg.say_bye()\n",
        "      return response\n",
        "  \n",
        "    return self.nlg.say_nounderstand()\n",
        "\n",
        "  def _order_logic(self, user_message):\n",
        "    \"\"\"Logica asociada a la seleccion de la comanda\"\"\"\n",
        "\n",
        "    user_message = user_message.replace(\" y \", \",\")\n",
        "    possible_item_id = [pid.strip() for pid in user_message.split(\",\")]\n",
        "    menu_item = self.backend.get_menu_item(possible_item_id)\n",
        "\n",
        "    if len(menu_item)>0:\n",
        "      # Cambia el estado del gestor de conversacion (se acabo la comanda)\n",
        "      self.order_state = False\n",
        "      assigned_order_id = self.backend.new_order(menu_item)\n",
        "      response = self.nlg.say_complete_order(menu_item, assigned_order_id)\n",
        "      return response\n",
        "    else:\n",
        "      # El usuario escribio algo q no es una comand\n",
        "      intent, entities = self.nlu_component(user_message)\n",
        "\n",
        "      if intent == \"menu\":\n",
        "        menu_data = self.backend.get_menu()\n",
        "        response = self.nlg.say_menu(menu_data)\n",
        "        response += f\"\\n {self.nlg.say_order_question()}\"\n",
        "        return response\n",
        "\n",
        "      if intent == \"cancel\":\n",
        "        # Cambia el estado del gestor de conversacion (se cierra la comanda)\n",
        "        self.order_state = False\n",
        "        response = self.nlg.say_cancel_accept()\n",
        "        return response\n",
        "\n",
        "      if intent == \"bye\":\n",
        "        # Cambia el estado del gestor de conversacion (se cierra la comunicacion)\n",
        "        self.close_conversation = True\n",
        "        response = self.nlg.say_bye()\n",
        "        return response\n",
        "  \n",
        "      return self.nlg.say_nounderstand()"
      ],
      "metadata": {
        "id": "Wn6p_kIAJ7vO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmjrntxizhUW"
      },
      "source": [
        "### Canal de comunicación\n",
        "\n",
        "Componente encargado de ofrecer una vía de interacción con el usuario."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HbR2mzf-1UvK"
      },
      "outputs": [],
      "source": [
        "def channel(conversation_manager):\n",
        "\n",
        "    # Chatbot inicia conversacion?\n",
        "    initial_sms = conversation_manager.init_conversation()\n",
        "    if len(initial_sms)>0:\n",
        "        print(f\"Bea: {initial_sms} \\n\")\n",
        "\n",
        "    while True:\n",
        "        text = str(input('Yo: '))\n",
        "\n",
        "        response = conversation_manager.logic(text)\n",
        "        print(f\"Bea: {response} \\n\")\n",
        "\n",
        "        if conversation_manager.is_last_message():\n",
        "          break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xz34fD9ARpx-"
      },
      "source": [
        "### Implementaciones de NLU\n",
        "\n",
        "Este componente es el que interpreta los mensajes del usuario en Lenguaje Natural y extrae el *Intent* y las *Entities*."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Basado en patrones"
      ],
      "metadata": {
        "id": "sXv24yVuewJG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LC7GRkYS1ZbG"
      },
      "source": [
        "En esta implementación trataremos de identificar de forma manual alguno de los términos más frecuentes entre los posibles mensajes de cada `intent`. Al mismo tiempo, tenemos que tener en cuenta que no sean términos comunes en el resto de `intents`.\n",
        "\n",
        "De esta forma podremos identificar con precisión el `intent` asociado a cada mensaje por la presencia o ausencia de cada uno de estos términos clave.\n",
        "\n",
        "Este principio es el mismo que usamos en [`TF-IDF` (term frequency-inverse document frequency)](https://monkeylearn.com/blog/what-is-tf-idf). El cual sería factible en caso de contar con una cantidad elevada de ejemplos etiquetados. \n",
        "\n",
        "![TF-IDF](https://miro.medium.com/max/943/1*HZvxT29V9B4HxT2wx8M4XQ.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_gB7q4_3gW6"
      },
      "outputs": [],
      "source": [
        "def check_some_expression_in_sms(expresions, user_message):\n",
        "  \"\"\"Comprueba si alguna de las expresiones dadas estan en el mensaje de entrada\"\"\"\n",
        "  if len([expresion for expresion in expresions if expresion in user_message.lower()])>0:\n",
        "    return True\n",
        "  return False\n",
        "\n",
        "def patternBasedNLU(user_message):\n",
        "  \"\"\"\n",
        "  Componente NLU que pretende identificar el INTENT en base a `palabras` \n",
        "  presentes en el mensaje.\n",
        "  Por ejemplo: si la palabra `horario` esta en el mensaje la intencion del\n",
        "  usuario probablemente sea consultar el horario de la cafeteria.   \n",
        "  \"\"\"\n",
        "\n",
        "  # - Identifica si el mensaje es relativo al intent : timetable\n",
        "  timetable_patterns = [\"horario\", \"hora\", \"cierre\", \"abrir\"]\n",
        "  if check_some_expression_in_sms(timetable_patterns, user_message):\n",
        "    return \"timetable\", None\n",
        "  \n",
        "  # - Identifica si el mensaje es relativo al intent : menu\n",
        "  menu_patterns = [\"menú\", \"menu\"] # Rellenar!!!\n",
        "  if check_some_expression_in_sms(menu_patterns, user_message):\n",
        "    return \"menu\", None\n",
        "  \n",
        "  # - Identifica si el mensaje es relativo al intent : order\n",
        "  order_patterns = [\"pedir\"] # Rellenar!!!\n",
        "  if check_some_expression_in_sms(order_patterns, user_message):\n",
        "    return \"order\", None\n",
        "  \n",
        "  # - Identifica si el mensaje es relativo al intent : cancel\n",
        "  cancel_patterns = [\"cancela\"] # Rellenar!!!\n",
        "  if check_some_expression_in_sms(cancel_patterns, user_message):\n",
        "    return \"cancel\", None\n",
        "  \n",
        "  # - Identifica si el mensaje es relativo al intent : bye\n",
        "  bye_patterns = [\"adios\"] # Rellenar!!!\n",
        "  if check_some_expression_in_sms(bye_patterns, user_message):\n",
        "    return \"bye\", None\n",
        "\n",
        "  return \"no_understand\", None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YuwIr0qP2XXF",
        "outputId": "26c3eb6c-91f0-4b3f-8237-a5764d6085ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bea: Hola, mi nombre es Bea.\n",
            "Soy el chatbot de tu cafetería de referencia y mi objetivo es ayudarte con tus consultas y peticiones. Solo dime qué quieres que haga por ti.\n",
            "Puedes preguntarme los siguientes comandos:\n",
            "      - Escribe: `horario` para conocer nuestro horario de apertura.\n",
            "      - Escribe: `menu` para conocer nuestra carta.\n",
            "      - Escribe: `pedir` para pedir algo de nuestra carta. \n",
            "\n",
            "Yo: horario\n",
            "Bea: El Lunes nuestro horario 08:30-20:00.\n",
            "Los Martes, Miércoles y Jueves nuestro horario es 08:00-20:00.\n",
            "El Viernes nuestro horario 08:00-17:00. \n",
            "\n",
            "Yo: menu\n",
            "Bea: Nuestras opciones en la carta son : \n",
            " - Bocadillo de jamón serrano por 5.3 euros. Código de comanda: 1\n",
            " - Bocadillo de queso por 4.0 euros. Código de comanda: 2\n",
            " - Bocadillo de bacon y queso por 5.0 euros. Código de comanda: 3\n",
            " - Pechuga de pollo por 6.0 euros. Código de comanda: 4\n",
            " - Tofu con pure de guisantes por 7.0 euros. Código de comanda: 5\n",
            " - Pimientos rellenos de champiñones por 6.0 euros. Código de comanda: 6\n",
            " - Agua por 0.8 euros. Código de comanda: 7\n",
            " - Coca-Cola por 1.1 euros. Código de comanda: 8 \n",
            "\n",
            "Yo: pedir\n",
            "Bea: Indica el código(s) de comanda de tu selección (p. ej., '1, 7' para seleccionar la opción 1 y 7): \n",
            "\n",
            "Yo: 1, 7\n",
            "Bea: Has seleccionado: Bocadillo de jamón serrano y Agua \n",
            "El total de tu pedido asciende a 6.1 euros.\n",
            "Tu pedido tiene el ID : 'BEA1'.\n",
            "Pasa por la barra en un rato a recogerlo! \n",
            "\n",
            "Yo: adios\n",
            "Bea: Gracias por tu visita, vuelve pronto! \n",
            "\n"
          ]
        }
      ],
      "source": [
        "cm = ConversationManager(nlu_component=patternBasedNLU, static_patterns=True)\n",
        "channel(cm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bsDyJZ3RxCl"
      },
      "source": [
        "#### Basado en similitud de oraciones\n",
        "\n",
        "En este caso buscamos la similitud semántica entre oraciones, ¿dicen algo similar aún escritas de forma diferente?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Sentence Similarity"
      ],
      "metadata": {
        "id": "oCWhogikf5Ou"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLkrJWTHnDAn"
      },
      "source": [
        "Para calcular cómo de similares son oraciones utilizaremos una red neuronal de NLP que nos permite convertir textos en embeddings. Un *embedding* es un vector matemático (ej. `[0.23824, 0.38510, 1.05822]`) que representa el texto como un punto en un espacio multidimensional. \n",
        "\n",
        "Por ejemplo, en la siguiente imagen cada palabra es convertida a embedding y, tras reducir su dimensión, representada en un grafo 2D.  \n",
        "\n",
        "![alt text](https://i.stack.imgur.com/nlEz7.png)\n",
        "\n",
        "En este caso concreto vamos a utilizar el modelo `hiiamsid/sentence_similarity_spanish_es` disponible a través de HuggingFace:\n",
        "https://huggingface.co/hiiamsid/sentence_similarity_spanish_es\n",
        "\n",
        "Primero cargamos el tokenizador (que convierte el texto a valores válidos de entrada al modelo) y el modelo (que convierte el texto tokenizado a embeddings de salida)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "enDq51EyW0o0"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "\n",
        "# Cargamos el tokenizador y el model de HuggingFace Hub\n",
        "tokenizer = AutoTokenizer.from_pretrained('hiiamsid/sentence_similarity_spanish_es')\n",
        "model = AutoModel.from_pretrained('hiiamsid/sentence_similarity_spanish_es')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nJLTtcfXkvK"
      },
      "source": [
        "Funciones para obtener el embedding de una oración usando el tokenizador y el modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FwaWkASB1124"
      },
      "outputs": [],
      "source": [
        "# Mean Pooling - Calcula el embedding usando la attention mask para corregir la media\n",
        "def mean_pooling(model_output, attention_mask):\n",
        "    token_embeddings = model_output[0] # El primer elemento contiene todos los embeddings de los tokens\n",
        "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
        "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
        "\n",
        "\n",
        "# Obtiene el embedding de una frase\n",
        "def sentence_embedding(sentence: str):\n",
        "\n",
        "  # Tokeniza la frase\n",
        "  encoded_input = tokenizer(sentence, padding=True, truncation=True, return_tensors='pt')\n",
        "\n",
        "  # Usa el modelo para predecir los embeddings de todos los tokens de la frase\n",
        "  with torch.no_grad():\n",
        "      model_output = model(**encoded_input)\n",
        "\n",
        "  # Calcula el embedding de la frase completa\n",
        "  return mean_pooling(model_output, encoded_input['attention_mask'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zDw5BshXwjY"
      },
      "source": [
        "Probamos que funciona"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2EYd572U-8Y",
        "outputId": "b1a429a2-bf3e-46f7-aa2c-b449e4d9cf63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El vector/embedding de salida tiene la forma: [1, 768]\n",
            "\n",
            "Embedding : [ 0.8512957096099854 ,  -0.3589854836463928 ,  0.15464350581169128 , ...,  -0.40280669927597046 ]\n"
          ]
        }
      ],
      "source": [
        "sentence = \"Hola mundo\"\n",
        "emb = sentence_embedding(sentence)\n",
        "\n",
        "print(f\"El vector/embedding de salida tiene la forma: {list(emb.shape)}\\n\")\n",
        "\n",
        "# Representacion controlada para evitar visualizar un vector de grandes proporciones por pantalla\n",
        "print(\"Embedding : [\", list(emb[0])[0].item(), \", \", list(emb[0])[1].item(), \", \", list(emb[0])[2].item(), \", ..., \", list(emb[0])[-1].item(), \"]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sjjcyax0YaVb"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "Una vez disponemos de los embeddings podemos aplicar algún método mátemático para conocer la distancia o similitud entre los vectores.\n",
        "\n",
        "En este caso, vamos a aplicar [similitud del coseno](https://towardsdatascience.com/understanding-cosine-similarity-and-its-application-fd42f585296a):\n",
        "\n",
        "![cosine_similarity_func](https://miro.medium.com/max/494/1*EoRUdEW02wzbLCT0VuTzXQ.png)\n",
        "\n",
        "Para su calculo usaremos directamente la librería `sklearn`.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7dzLPSEXYaet"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def sentence_similarity(sentence1, sentence2):\n",
        "  \"\"\"Calcula la similitud de dos oraciones\"\"\"\n",
        "\n",
        "  # Calculamos los embeddings\n",
        "  if type(sentence1) == str:\n",
        "    sentence1 = sentence_embedding(sentence1)\n",
        "  if type(sentence2) == str:\n",
        "    sentence2 = sentence_embedding(sentence2)\n",
        "\n",
        "  # Calculamos la similitud del coseno basada en los embeddings\n",
        "  return cosine_similarity(sentence1, sentence2).item()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nHwsH4YmzOn"
      },
      "source": [
        "Visualizamos un ejemplo de calculo de similitud entre frases. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asDbKkS1ouIW",
        "outputId": "ccb22d94-8663-47ff-c6f7-586bec07e380"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Oración de referencia : Esa es una persona feliz \n",
            "\n",
            "- Ese es un perro feliz \t (0.4153728485107422)\n",
            "- Esa es una persona muy feliz \t (0.9393529891967773)\n",
            "- Hoy es un día soleado \t (0.18199917674064636)\n"
          ]
        }
      ],
      "source": [
        "# Frase de referencia\n",
        "reference = \"Esa es una persona feliz\"\n",
        "\n",
        "# Frases para comparar\n",
        "sentence1 = \"Ese es un perro feliz\"\n",
        "sentence2 = \"Esa es una persona muy feliz\"\n",
        "sentence3 = \"Hoy es un día soleado\"\n",
        "\n",
        "print(f\"Oración de referencia : {reference} \\n\")\n",
        "print(f\"- {sentence1} \\t ({sentence_similarity(reference, sentence1)})\")\n",
        "print(f\"- {sentence2} \\t ({sentence_similarity(reference, sentence2)})\")\n",
        "print(f\"- {sentence3} \\t ({sentence_similarity(reference, sentence3)})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iH_qsbSiknG-"
      },
      "source": [
        "##### Ejemplos de INTENTS\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuación, definimos algunos ejemplos de mensajes esperados por cada intent. Para ello, seguiremos el mismo formato que se define en [RASA](https://rasa.com/docs/rasa/training-data-format/). "
      ],
      "metadata": {
        "id": "yaXU8ZV2f8Ca"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7rYCMsJ6bq6k"
      },
      "outputs": [],
      "source": [
        "text = \"\"\"\n",
        "nlu:\n",
        "\n",
        "- intent: bye\n",
        "  examples: |\n",
        "    - adios\n",
        "    - bye\n",
        "    - chao\n",
        "\n",
        "- intent: timetable\n",
        "  examples: |\n",
        "    - que horario teneis\n",
        "    - que horas estais abiertos\n",
        "    - a que hora cerrais\n",
        "    - estais abiertos ahora\n",
        "    - abris por la mañana\n",
        "    - abris por la tarde\n",
        "    - abris por la noche\n",
        "    - hay servicio hoy\n",
        "    - seguireis dando servicio en una hora\n",
        "    - cuando abris\n",
        "    - esta semana esta la cafeteria en servicio\n",
        "    - horario de apertura\n",
        "  \n",
        "- intent: menu\n",
        "  examples: |\n",
        "    - enseñame el menu de la cafeteria\n",
        "    # Escribe aqui ejemplos para solicitar visualizar el menu\n",
        "\n",
        "\n",
        "- intent: order\n",
        "  examples: |\n",
        "    - quisiera hacer un pedido\n",
        "    # Escribe aqui ejemplos para solicitar lanzar comandas\n",
        "\n",
        "- intent: cancel\n",
        "  examples: |\n",
        "    - cancela el proceso actual\n",
        "    # Escribe aqui ejemplos para cancelar un proceso que se ha iniciado\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# %store text > nlu.yml\n",
        "with open('nlu.yml', 'w') as f:\n",
        "    f.write(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJF4pPYxv3nx"
      },
      "source": [
        "##### NLU basado en Sentence Similarity "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finalmente, implementamos un componente NLU que aplique sentence similarity a los mensajes de entrada contra cada uno de los mensajes de ejemplo, hasta identificar el *intent* mas probable. "
      ],
      "metadata": {
        "id": "G7eoIToCgAu2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4JORjkL_qva7"
      },
      "outputs": [],
      "source": [
        "import yaml\n",
        "import numpy as np\n",
        "\n",
        "class SentenceSimilarityBasedNLU:\n",
        "  similarity_threshold = None\n",
        "\n",
        "  def __init__(self, nlu_input_filepath = \"./nlu.yml\",\n",
        "               similarity_threshold:float = 0.2):\n",
        "    self.similarity_threshold = similarity_threshold\n",
        "    self.nlu_input_filepath = nlu_input_filepath\n",
        "    self.nlu_inputs = self.load_nlu_inputs()\n",
        "  \n",
        "  def load_nlu_inputs(self) -> dict:\n",
        "    \"\"\"Carga los ejemplos de NLU\"\"\"\n",
        "    with open(self.nlu_input_filepath, 'r') as stream:\n",
        "        try:\n",
        "            data = yaml.safe_load(stream)\n",
        "        except yaml.YAMLError as exc:\n",
        "            print(\"The NLU file is not properly formated. Review it before continuing. \")\n",
        "            print(\"Exception: \", exc)\n",
        "            raise exc\n",
        "        intents = {}\n",
        "        for entry in data['nlu']:\n",
        "          intent = entry['intent']\n",
        "          examples = [intent_ex.replace(\"-\",\"\").strip() for intent_ex in entry['examples'].splitlines()]\n",
        "          intents[intent] = [sentence_embedding(example) for example in examples]\n",
        "        return intents\n",
        "\n",
        "  def __call__(self, user_message):\n",
        "    max_sim_score = -1\n",
        "    max_sim_intent = None\n",
        "\n",
        "    # Calcula el embedding del mensaje de entrada\n",
        "    user_message_emb = sentence_embedding(user_message)\n",
        "\n",
        "    # Recorre cada intent \n",
        "    for intent in self.nlu_inputs:\n",
        "      # Recorre cada ejemplo del intent\n",
        "      for example in self.nlu_inputs[intent]:\n",
        "\n",
        "        # Calcula similitud entre el mensaje del usuario y el ejemplo del intent\n",
        "        similarity = sentence_similarity(user_message_emb, example)\n",
        "\n",
        "        if similarity > 0.98:\n",
        "          return intent, None\n",
        "\n",
        "        # Similitud superior al umbral y a la ultima maxima similitud\n",
        "        if similarity > self.similarity_threshold and similarity > max_sim_score :\n",
        "          max_sim_score = similarity\n",
        "          max_sim_intent = intent\n",
        "                \n",
        "    return max_sim_intent, None"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lanzamos el chatbot"
      ],
      "metadata": {
        "id": "8vFmsi4JgVoy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9326ksTh1uH",
        "outputId": "959e8076-7281-443b-f538-9b7294699341"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bea: Hola, mi nombre es Bea.\n",
            "Soy el chatbot de tu cafetería de referencia y mi objetivo es ayudarte con tus consultas y peticiones. Solo dime qué quieres que haga por ti. \n",
            "\n",
            "Yo: cuando estais abiertos\n",
            "Bea: El Lunes nuestro horario 08:30-20:00.\n",
            "Los Martes, Miércoles y Jueves nuestro horario es 08:00-20:00.\n",
            "El Viernes nuestro horario 08:00-17:00. \n",
            "\n",
            "Yo: muestrame el menu de la cafeteria\n",
            "Bea: Nuestras opciones en la carta son : \n",
            " - Bocadillo de jamón serrano por 5.3 euros. Código de comanda: 1\n",
            " - Bocadillo de queso por 4.0 euros. Código de comanda: 2\n",
            " - Bocadillo de bacon y queso por 5.0 euros. Código de comanda: 3\n",
            " - Pechuga de pollo por 6.0 euros. Código de comanda: 4\n",
            " - Tofu con pure de guisantes por 7.0 euros. Código de comanda: 5\n",
            " - Pimientos rellenos de champiñones por 6.0 euros. Código de comanda: 6\n",
            " - Agua por 0.8 euros. Código de comanda: 7\n",
            " - Coca-Cola por 1.1 euros. Código de comanda: 8 \n",
            "\n",
            "Yo: hacer un pedido\n",
            "Bea: Indica el código(s) de comanda de tu selección (p. ej., '1, 7' para seleccionar la opción 1 y 7): \n",
            "\n",
            "Yo: 3,8\n",
            "Bea: Has seleccionado: Bocadillo de bacon y queso y Coca-Cola \n",
            "El total de tu pedido asciende a 6.1 euros.\n",
            "Tu pedido tiene el ID : 'BEA1'.\n",
            "Pasa por la barra en un rato a recogerlo! \n",
            "\n",
            "Yo: adios\n",
            "Bea: Gracias por tu visita, vuelve pronto! \n",
            "\n"
          ]
        }
      ],
      "source": [
        "cm = ConversationManager(nlu_component=SentenceSimilarityBasedNLU())\n",
        "channel(cm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHqPe_m0wKi7"
      },
      "source": [
        "#### Basado en Rasa NLU\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este caso utilizamos el componente NLU de la librería [Rasa](https://rasa.com/docs/rasa/).\n",
        "\n",
        "Este componente utiliza algoritmos propios de IA para la identificación de *Intents* y *Entitities*"
      ],
      "metadata": {
        "id": "78hiS90Mga9w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Ejemplos de INTENTS y ENTITIES"
      ],
      "metadata": {
        "id": "9iXHAhdJhcUR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los ejemplos dados sirven para entrenar el componente. Para que el algoritmo sepa interpretar los datos, estos deben seguir un [formato específico](https://rasa.com/docs/rasa/training-data-format/) y ser exportados en un fichero YAML.\n",
        "\n",
        "Además, para afinar el NLU es posible [incluír datos de entrenamiento específicos como sinónimos, tablas de *lookup* o expresiones regulares](https://rasa.com/docs/rasa/nlu-training-data/).\n",
        "\n",
        "En este caso reutilizaremos el `nlu.yml` creado en la sección anterior ya que incluía diferentes ejemplos siguiendo ya el formato de Rasa. A estos ejemplos ya existentes añadiremos (append) nuevos ejemplos con definición de *Entities*."
      ],
      "metadata": {
        "id": "E865VEAYht6S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fOiu08eqmAXF"
      },
      "outputs": [],
      "source": [
        "text = \"\"\"\n",
        "- intent: greet\n",
        "  examples: |\n",
        "    - hey\n",
        "    - hola\n",
        "    - buenas\n",
        "    - hola Bea\n",
        "    - buenos dias\n",
        "    - buenas tardes\n",
        "    - buenas noches\n",
        "    - un placer conocerte Bea\n",
        "    - que casualidad, yo también me llamo [Bea](username)\n",
        "    - hola Bea, soy [Victor](username)\n",
        "    - mi nombre es [Almudena](username), encantada de conocerte\n",
        "    - buenas, me llamo [Sonia](username)\n",
        "    - soy [Alberto](username)\n",
        "    - llámame [Maria](username)\n",
        "    - hola Bea, soy [Juan](username)\n",
        "\n",
        "- lookup: username\n",
        "  examples: |\n",
        "    - Alejandra\n",
        "    - Sergio\n",
        "    - Valentina\n",
        "    # Escribe mas posibles nombre    \n",
        "\n",
        "\n",
        "- intent: check_order\n",
        "  examples: |\n",
        "    - mi pedido [BEA1001](asked_order_id) esta disponible\n",
        "    - puedo pasar a recoger la comanda [BEA1](asked_order_id)\n",
        "    - está [BEA85](asked_order_id) listo?\n",
        "    - la orden [BEA092](asked_order_id) esta en la barra?\n",
        "    - [BEA77](asked_order_id) está cocinado?\n",
        "    - tenéis ya por ahí el menú [BEA254](asked_order_id)    \n",
        "\n",
        "- regex: asked_order_id\n",
        "  examples: |\n",
        "    - BEA\\d{1,10}\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "with open('nlu.yml', 'a') as f:\n",
        "    f.write(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Configuración Rasa NLU"
      ],
      "metadata": {
        "id": "dkP7s4KTi0Kz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La configuración de Rasa NLU se basa en pipelines. Es decir, en la definición de los componentes (y sus configuraciones) y la secuencia de ejecución para llegar a la identificación de *intents* y *entities*. \n",
        "\n",
        "Los [componentes del pipeline](https://rasa.com/docs/rasa/components/#languagemodelfeaturizer) permiten realizar diferentes análisis (vectorización, tokenización, clasificación, etc.) y sus resultados sirven de entrada al siguiente componente. Además, es posible definir componentes propios.\n",
        "\n",
        "En el caso del componente principal el que realiza el paso de clasificar los *intents* y *entities*, usaremos el [*DIET Classifier*](https://www.youtube.com/watch?v=vWStcJDuOUk). Este modelo alcanza el *State of The Art* en la actualidad (aka, principios de 2022).\n",
        "\n",
        "![DIET Classifier](https://miro.medium.com/max/1400/1*Y_sBnCaJyo4poREWdBS3Wg.gif)\n",
        "\n",
        "A modo de ejemplo, la configuración propuesta es:"
      ],
      "metadata": {
        "id": "i_4sptTTjDH-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"\n",
        "recipe: default.v1\n",
        "\n",
        "language: es\n",
        "\n",
        "pipeline:\n",
        "  - name: WhitespaceTokenizer\n",
        "  - name: LanguageModelFeaturizer\n",
        "    model_weights: \"dccuchile/bert-base-spanish-wwm-cased\"\n",
        "    model_name: \"bert\"\n",
        "  - name: CountVectorsFeaturizer\n",
        "  - name: LexicalSyntacticFeaturizer\n",
        "  - name: RegexFeaturizer\n",
        "  - name: DIETClassifier\n",
        "    random_seed: 42\n",
        "    use_masked_language_model: True\n",
        "    epochs: 100\n",
        "    number_of_transformer_layer: 4\n",
        "    transformer_size: 256\n",
        "    drop_rate: 0.2\n",
        "    weight_sparsity: 0.7\n",
        "  - name: EntitySynonymMapper\n",
        "\"\"\"\n",
        "\n",
        "# %store text > config.yml\n",
        "with open('rasa_config.yml', 'w') as f:\n",
        "    f.write(text)"
      ],
      "metadata": {
        "id": "prwxr6xXjOWK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QYnS696sBiFj"
      },
      "outputs": [],
      "source": [
        "from rasa import model_training\n",
        "model_path = model_training.train_nlu(\n",
        "    config=\"./rasa_config.yml\",\n",
        "    nlu_data=\"./nlu.yml\",\n",
        "    output=\"./rasa_models/\"\n",
        "  )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDcqxja0n_6N"
      },
      "source": [
        "##### NLU basado en RASA NLU "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finalmente, implementamos un componente NLU que aplique RASA NLU a los mensajes de entrada  pare identificar el *intent* y *entities* mas probable. "
      ],
      "metadata": {
        "id": "-5koBvk9uF0-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGPMkZvSBKvO",
        "outputId": "2ce6ee76-cab2-4668-bd52-dead27250440"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Event loop ready.\n"
          ]
        }
      ],
      "source": [
        "# Para usar asincronia en Google Colab\n",
        "import nest_asyncio\n",
        "\n",
        "nest_asyncio.apply()\n",
        "print(\"Event loop ready.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q59VLdatn_6N"
      },
      "outputs": [],
      "source": [
        "import rasa\n",
        "import asyncio\n",
        "\n",
        "class RasaBasedNLU:\n",
        "\n",
        "  def __init__(self, model_path = \"./rasa_model\",\n",
        "               intent_threshold:float = 0.4):    \n",
        "    self.agent = asyncio.run(rasa.core.agent.load_agent(model_path=model_path))\n",
        "    self.intent_threshold = intent_threshold\n",
        "  \n",
        "\n",
        "  def __call__(self, user_message):\n",
        "    \n",
        "    # Run NLU model\n",
        "    result = asyncio.run(self.agent.parse_message(user_message))\n",
        "\n",
        "    # Intent\n",
        "    if result[\"intent\"][\"confidence\"]> self.intent_threshold:\n",
        "        return result[\"intent\"][\"name\"], result[\"entities\"]\n",
        "\n",
        "    return \"not_found\", None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZM5OhOPn_6N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fba88e87-1d9c-43d1-de75-9106506fb0aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[93m/usr/local/lib/python3.7/dist-packages/rasa/shared/core/slot_mappings.py:217: UserWarning: Slot auto-fill has been removed in 3.0 and replaced with a new explicit mechanism to set slots. Please refer to https://rasa.com/docs/rasa/domain#slots to learn more.\n",
            "  UserWarning,\n",
            "\u001b[0mSome layers from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased were not used when initializing TFBertModel: ['mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some layers of TFBertModel were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased and are newly initialized: ['bert/pooler/dense/kernel:0', 'bert/pooler/dense/bias:0']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/cond_1_grad/gradients/cond_1/GatherV2_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/cond_1_grad/gradients/cond_1/GatherV2_grad/Reshape:0\", shape=(None,), dtype=float32), dense_shape=Tensor(\"gradients/cond_1_grad/gradients/cond_1/GatherV2_grad/Cast:0\", shape=(1,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "\u001b[93m/usr/local/lib/python3.7/dist-packages/rasa/utils/train_utils.py:530: UserWarning: constrain_similarities is set to `False`. It is recommended to set it to `True` when using cross-entropy loss.\n",
            "  category=UserWarning,\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "cm = ConversationManager(nlu_component=RasaBasedNLU(model_path=model_path))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "channel(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fh3hwd9yNVQg",
        "outputId": "91fa9d48-398b-4e4e-9186-f98020e12865"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bea: Hola, mi nombre es Bea.\n",
            "Soy el chatbot de tu cafetería de referencia y mi objetivo es ayudarte con tus consultas y peticiones. Solo dime qué quieres que haga por ti. \n",
            "\n",
            "Yo: Hola Bea, soy Victor\n",
            "Bea: Buenas Victor, ¿qué puedo hacer por ti? \n",
            "\n",
            "Yo: Me gustaria saber si estais abiertos\n",
            "Bea: El Lunes nuestro horario 08:30-20:00.\n",
            "Los Martes, Miércoles y Jueves nuestro horario es 08:00-20:00.\n",
            "El Viernes nuestro horario 08:00-17:00. \n",
            "\n",
            "Yo: Muestrame la carta\n",
            "Bea: Nuestras opciones en la carta son : \n",
            " - Bocadillo de jamón serrano por 5.3 euros. Código de comanda: 1\n",
            " - Bocadillo de queso por 4.0 euros. Código de comanda: 2\n",
            " - Bocadillo de bacon y queso por 5.0 euros. Código de comanda: 3\n",
            " - Pechuga de pollo por 6.0 euros. Código de comanda: 4\n",
            " - Tofu con pure de guisantes por 7.0 euros. Código de comanda: 5\n",
            " - Pimientos rellenos de champiñones por 6.0 euros. Código de comanda: 6\n",
            " - Agua por 0.8 euros. Código de comanda: 7\n",
            " - Coca-Cola por 1.1 euros. Código de comanda: 8 \n",
            "\n",
            "Yo: Quisiera hacer un pedido\n",
            "Bea: Indica el código(s) de comanda de tu selección (p. ej., '1, 7' para seleccionar la opción 1 y 7): \n",
            "\n",
            "Yo: 1, 3, 8\n",
            "Bea: Has seleccionado: Bocadillo de jamón serrano, Bocadillo de bacon y queso y Coca-Cola \n",
            "El total de tu pedido asciende a 11.4 euros.\n",
            "Tu pedido tiene el ID : 'BEA1'.\n",
            "Pasa por la barra en un rato a recogerlo! \n",
            "\n",
            "Yo: Tienes disponible el pedido BEA3\n",
            "Bea: Tu comanda con id BEA3 está disponible. Pasa por la barra a recogerla. \n",
            "\n",
            "Yo: adios\n",
            "Bea: Gracias por tu visita, vuelve pronto! \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusiones\n",
        "\n"
      ],
      "metadata": {
        "id": "fzUfzMUS6EN4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Un chatbot es un proceso lógico basado en la interacción y coordinación de diferentes componentes. Estos pueden variar de lo más complejo a lo más simple y los resultados varian en consonancia.\n",
        "\n",
        "En este notebook hemos visto un ejemplo muy básico de chatbot pero que nos ofrece un primer acercamiento tanto al ámbito de los chatbots como a NLP. "
      ],
      "metadata": {
        "id": "7jgrliDQ6Kw6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejercicios\n",
        "\n",
        "¿Cómo harías para incluir la opción de consultar la carta pero mostrando solo la opción vegetariana? ¿Un nuevo *intent*?¿o *entity* en el *intent* ya existente? \n",
        "\n",
        "¿Cómo se podría consultar el horario de un día específico?¿Cómo hacer para informar si en el momento de la consulta la cafetería esta abierta o no?\n",
        "\n",
        "¿Y la opción de consultar por tipo de plato: bocadillos, platos combinados, bebidas, etc.? Piensa que el menú puede cambiar y ampliar la oferta.\n",
        "\n",
        "¿Sería posible hacer que se pueda pedir la comanda por el nombre de los platos? En caso posible (que lo es), ¿qué pasaría cuando el nombre que da el usuario no sea exactamente igual al de la carta?¿Podrías solucionarlo en el NLU (ver [sinónimos](https://rasa.com/docs/rasa/nlu-training-data#synonyms))?\n",
        "\n",
        "¿Crees que podrías hacer tu propio chatbot? Anímate.\n",
        "\n",
        "Cualquier duda o comentario estoy encantado de contestarte: [linkedin](https://www.linkedin.com/in/victor-roris)"
      ],
      "metadata": {
        "id": "gl72hxuoAGmW"
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "LC7GRkYS1ZbG"
      ],
      "name": "Workshop-Chatbot_ES.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN1BGblmGauGcKIaig8IYUu",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}